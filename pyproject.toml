[project]
name = "autotune"
version = "0.1.0"
description = "Educational LLM post-training project - learn SFT, RLHF, and DPO"
readme = "README.md"
requires-python = ">=3.12"
dependencies = [
    "torch>=2.5.0",
    "transformers>=4.46.0",
    "datasets>=4.3.0",
    "accelerate>=1.2.0",
    "peft>=0.13.0",  # For LoRA/parameter-efficient fine-tuning
    "trl>=0.12.0",  # Transformer Reinforcement Learning library
    "rich>=14.2.0",
    "questionary>=2.1.0",
    "numpy>=1.26.0",
    "tqdm>=4.66.0",
]

[project.optional-dependencies]
rocm = [
    "torch>=2.5.0; sys_platform == 'linux'",
    "pytorch-triton-rocm; sys_platform == 'linux'",
]

[dependency-groups]
dev = [
    "pytest>=8.4.2",
    "pytest-cov>=7.0.0",
]

# PyTorch backend configuration
# By default, uses PyPI torch (CUDA on Linux, CPU elsewhere)
# For AMD GPUs (Linux only): uv sync --extra rocm
[[tool.uv.index]]
name = "pytorch-rocm"
url = "https://download.pytorch.org/whl/rocm6.2"
explicit = true

